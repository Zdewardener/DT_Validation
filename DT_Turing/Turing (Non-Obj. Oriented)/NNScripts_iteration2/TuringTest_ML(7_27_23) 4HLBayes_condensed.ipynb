{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0qEK89j1kPrj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%pip install wandb -qU\n","%pip install --no-deps scikeras\n","%pip install tensorflow-addons"],"metadata":{"id":"kBSGkbCrkPoy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRi3sFCA0iPM"},"outputs":[],"source":["#imports\n","import os\n","import wandb\n","from wandb.keras import WandbCallback\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras import backend as K\n","import tensorflow as tf\n","from scikeras.wrappers import KerasClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.model_selection import cross_val_predict\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import seaborn as sns\n","from sklearn.metrics import roc_auc_score\n","import tensorflow_addons as tfa\n","from sklearn import preprocessing\n","from sklearn.preprocessing import MinMaxScaler\n","import tensorflow\n","from keras.optimizers import SGD\n","from keras.layers import Dropout"]},{"cell_type":"markdown","metadata":{"id":"qPTej9HDF3Pk"},"source":["**Data processing **"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AoNlkHHYTxuS"},"outputs":[],"source":["# gpus = tf.config.experimental.list_physical_devices('GPU')\n","\n","# if gpus:\n","#     try:\n","#         # Use the first GPU\n","#         tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n","#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n","#     except RuntimeError as e:\n","#         # Visible devices must be set before GPUs have been initialized\n","#         print(e)\n","# else:\n","#     print('No GPU detected')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-E31Plr9iwaF"},"outputs":[],"source":["#-----------------------------------------------------------------------------------------------------------\n","#Upload Real Datasets\n","df_real1 = pd.read_csv('/content/drive/MyDrive/Lab Work/Zach/RealData/Blue Order 1 (Ready_4ML).csv')\n","df_real2 = pd.read_csv('/content/drive/MyDrive/Lab Work/Zach/RealData/Red Order 1 (REady_4ML).csv')\n","df_real3 = pd.read_csv('/content/drive/MyDrive/Lab Work/Zach/RealData/White Order 1 (Ready_4ML).csv')\n","\n","df_real1.rename(columns={'Run Time ': 'Run Time'}, inplace=True)\n","df_real2.rename(columns={'Run Time ': 'Run Time'}, inplace=True)\n","df_real3.rename(columns={'Run Time ': 'Run Time'}, inplace=True)\n","\n","\n","# Concatenating Real Datasets (Assuming df_real1, df_real2, and df_real3 are separate DataFrames)\n","\n","# Concatenate df_real2 and df_real3 first\n","concatenated_df = pd.concat([df_real2, df_real3])\n","\n","# Now, concatenate df_real1 with the previously concatenated DataFrame\n","df2 = pd.concat([df_real1, concatenated_df])\n","\n","# Alternatively, you can concatenate all DataFrames in one line\n","df2 = pd.concat([df_real1, df_real2, df_real3])\n","\n","#uncomment below print statements to see exactly what steps are followed\n","#################################################\n","#print(\"combined real dataset\", '\\n' ,df2)\n","#################################################\n","\n","#-----------------------------------------------------------------------------------------------------------\n","#Upload Simulated Dataset\n","df1 = pd.read_csv('/content/drive/MyDrive/Lab Work/Zach/mergedata/RWB_SimDataCombined.csv')\n","\n","# Rename the 'B' column to 'C' in-place\n","df1.rename(columns={'Run Time ': 'Run Time'}, inplace=True)\n","\n","#Create a TARGET[LABEL] column\n","df1['type'] = 0 #SimData\n","df2['type'] = 1 #RealData\n","df_combined = pd.concat([df1, df2])\n","\n","# Removing any extra spaces in the topics column\n","df_combined['topics'] = df_combined['topics'].apply(lambda x: x.replace(\" \", \"\"))\n","\n","#################################################\n","#print(\"combined Real & simulated dataset\", '\\n', df_combined)\n","#################################################\n","\n","#-----------------------------------------------------------------------------------------------------------\n","# label_encoder\n","# how to understand word labels.\n","label_encoder = preprocessing.LabelEncoder()\n","# Encode labels in column 'topics', 'msg', and 'node'.\n","df_combined['topics']= label_encoder.fit_transform(df_combined['topics'])\n","df_combined['msg']= label_encoder.fit_transform(df_combined['msg'])\n","df_combined['node']= label_encoder.fit_transform(df_combined['node'])\n","\n","#################################################\n","#print(\"combined dataset [encoded]\", '\\n', df_combined)\n","#################################################\n","\n","#-----------------------------------------------------------------------------------------------------------\n","#Setting our prediction target and dropping target columns from the main dataset\n","predict = 'type'\n","drops = ['Run Time', 'msg', 'node', 'topics']\n","X = df_combined.drop(predict, axis=1)\n","y = df_combined[predict]\n","print(X.head())\n","print(y.head())\n","\n","#-----------------------------------------------------------------------------------------------------------\\\n","#Train,test,split setup 70-30\n","X_train, X_test, y_train, y_test =  sklearn.model_selection.train_test_split(X, y, test_size=0.3, shuffle=True)\n","\n","print(f'Train y: {y_train.shape}')\n","print(f'Train X: {X_train.shape}')\n","print(f'Test y: {y_test.shape}')\n","print(f'Test X: {X_test.shape}')"]},{"cell_type":"markdown","metadata":{"id":"nBoMu3zGiwaG"},"source":["--------------------------\n","Weights and Biases Setup\n","--------------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZA4uQhOE1R--"},"outputs":[],"source":["#This cell will run continuously until an API key is pasted into an input box.\n","#If the input box does not show, cancel the cell and move on to the next where the same prompt will arise with an input box.\n","!wandb login --relogin"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RZ4qMFt1U-t"},"outputs":[],"source":["#defining notebook name for WandB sweep\n","#os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"TuringTest_ML(7_10_23) 4HLBayes.ipynb\"\n","\n","#sweep configuration\n","sweep_configuration = {\n","    'method': 'bayes',\n","    'name': 'sweep',\n","    'metric': {\n","        'goal': 'maximize',\n","        'name': 'f1_score'\n","\t\t},\n","    'parameters': {\n","        'batch_size': {'values': [10,15,25,32,50,64,75,100]},\n","        'epochs': {'values': [50,75,100,125,150,200,250,300]},\n","        'fc_layer_size': {'values': [7,9,11,13,15,20,25,30,50]},\n","        'sc_layer_size': {'values': [7,9,11,13,15,20,25,30,50]},\n","        'Td_layer_size': {'values': [7,9,11,13,15,20,25,30,50]},\n","        'Frth_layer_size': {'values': [7,9,11,13,15,20,25,30,50]},\n","        'lr': {'max': 0.1, 'min': 0.0001},\n","        'optimizer':{'values': ['adam','SGD','RMSprop','nadam','Adadelta','Adagrad','Adamax','Ftrl','AdamW']},\n","        'dropout': {'values': [0, 0.3, 0.5]},\n","     },\n","\n","}\n","\n","sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"NN_Turing\", entity=\"dt_zach\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DSYyA_9Y1VvV"},"outputs":[],"source":["#defining which optimizers the sweep will attempt to use\n","\n","def get_optimizer(lr=1e-3, optimizer=\"adam\"):\n","    \"Select optmizer between adam and sgd with momentum\"\n","    if optimizer.lower() == \"adam\":\n","        return tf.keras.optimizers.Adam(learning_rate=lr)\n","    if optimizer.lower() == \"sgd\":\n","        return tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.1)\n","    if optimizer.lower() == \"rmsprop\":\n","        return tf.keras.optimizers.RMSprop(learning_rate=lr)\n","    if optimizer.lower() == \"nadam\":\n","        return tf.keras.optimizers.Nadam(learning_rate=lr)\n","    if optimizer.lower() == \"adadelta\":\n","        return tf.keras.optimizers.Adadelta(learning_rate=lr)\n","    if optimizer.lower() == \"adagrad\":\n","        return tf.keras.optimizers.Adagrad(learning_rate=lr)\n","    if optimizer.lower() == \"adamax\":\n","        return tf.keras.optimizers.Adamax(learning_rate=lr)\n","    if optimizer.lower() == \"ftrl\":\n","        return tf.keras.optimizers.Ftrl(learning_rate=lr)\n","    if optimizer.lower() == \"adamw\":\n","        return tf.keras.optimizers.AdamW(learning_rate=lr)\n","\n","#define the initial NN for parameter sweep\n","#-----------------------------------------------------------------------------------------------------------\n","def Nerual_Net(fc_layer_size=11,sc_layer_size=7,Td_layer_size=7,Frth_layer_size=7,dropout=0):\n","  # Set the GPU as the backend for Keras <-------------------------------------------------------------------------$$$$$$$$$$$$$$$$__(ISSUE)__$$$$$$$$$$$$$$$$$$\n","  config = tf.compat.v1.ConfigProto()\n","  config.gpu_options.allow_growth = True\n","  sess = tf.compat.v1.Session(config=config)\n","  tf.compat.v1.keras.backend.set_session(sess)\n","  # initiate Network\n","  network = Sequential()\n","\n","  # input layer that is fully connected with ReLU activation\n","  network.add(Dense(4, input_dim=4, activation=\"relu\",use_bias=True,bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","  network.add(Dropout(dropout))\n","\n","  #hiddent layers\n","  network.add(Dense(fc_layer_size, activation=\"relu\", use_bias=True, bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","  network.add(Dropout(dropout))\n","  # 2nd hiddent layers\n","  network.add(Dense(sc_layer_size, activation=\"relu\", use_bias=True, bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","  network.add(Dropout(dropout))\n","  # 3rd hiddent layers\n","  network.add(Dense(Td_layer_size, activation=\"relu\", use_bias=True, bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","  network.add(Dropout(dropout))\n","  # 4th hidden layers\n","  network.add(Dense(Frth_layer_size, activation=\"relu\", use_bias=True, bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","\n","\n","  #Output layer that is fully connected with sigmoid activation\n","  network.add(Dense(1, activation=\"sigmoid\",kernel_initializer=\"glorot_normal\"))\n","\n","\n","  #return completed network\n","  return network\n","\n","#define the training behavior for the sweep\n","#-----------------------------------------------------------------------------------------------------------\n","def train(model, batch_size=64, epochs=10, lr=1e-3, optimizer='adam', log_freq=10):\n","\n","    # Compile model like you usually do.\n","    tf.keras.backend.clear_session()\n","    model.compile(optimizer=get_optimizer(lr, optimizer) ,\n","               loss=\"binary_crossentropy\",\n","               metrics=[\"binary_accuracy\",\n","               tfa.metrics.F1Score(num_classes=2,\n","                                  average='micro',\n","                                  threshold=0.5),\n","               tf.keras.metrics.AUC(from_logits=True)\n","                        ])\n","\n","    model.fit(X_train,\n","              y_train,\n","              batch_size=batch_size,\n","              epochs=epochs,\n","              validation_data=(X_test, y_test),\n","              callbacks=[WandbCallback()])\n","\n","    #More sweep configuirations for training\n","#-----------------------------------------------------------------------------------------------------------\n","def sweep_train(config_defaults=None):\n","    # Initialize wandb with a sample project name\n","    with wandb.init(config=config_defaults):  # this gets over-written in the Sweep\n","\n","        # Specify the other hyperparameters to the configuration, if any\n","        wandb.config.architecture_name = \"TestLabfab\"\n","        wandb.config.dataset_name = \"Labfab\"\n","\n","        # initialize model\n","        model = Nerual_Net(wandb.config.fc_layer_size,wandb.config.sc_layer_size,wandb.config.Td_layer_size,wandb.config.Frth_layer_size,wandb.config.dropout)\n","\n","        train(model,\n","              wandb.config.batch_size,\n","              wandb.config.epochs,\n","              wandb.config.lr,\n","              wandb.config.optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IRrxw-ov1ejM"},"outputs":[],"source":["#Sanity check\n","import pprint\n","pprint.pprint(sweep_configuration)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w1n8ckhR1gYz"},"outputs":[],"source":["#Sweep initialization for 150 combinations of parameters\n","wandb.agent(sweep_id, function=sweep_train, count=150)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cMxth3LO1i4j"},"outputs":[],"source":["run = wandb.init(project=\"NN_Turing\", entity=\"dt_zach\")"]},{"cell_type":"markdown","metadata":{"id":"lhmv-n3oG-Jh"},"source":["Testing the best model from Wandb Sweep"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cVbaiWwu1mWD"},"outputs":[],"source":["#Build the model\n","def Neural_Net():\n","\n","  # initiate Network\n","  network = Sequential()\n","\n","  # input layer that is fully connected with ReLU activation\n","  network.add(Dense(4, input_dim=4, activation=\"relu\",use_bias=True,bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","  network.add(Dropout(0))\n","  #hidden layers\n","  network.add(Dense(11, activation=\"relu\", use_bias=True, bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","  network.add(Dropout(0))\n","  network.add(Dense(13, activation=\"relu\", use_bias=True, bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","  network.add(Dropout(0))\n","  network.add(Dense(11, activation=\"relu\", use_bias=True, bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","  network.add(Dropout(0))\n","  network.add(Dense(30, activation=\"relu\", use_bias=True, bias_initializer=\"glorot_normal\", kernel_initializer=\"glorot_normal\"))\n","\n","  #Output layer that is fully connected with sigmoid activation\n","  network.add(Dense(1, activation=\"sigmoid\",kernel_initializer=\"glorot_normal\"))\n","\n","\n","  # Compile network model.\n","  network.compile(optimizer=get_optimizer(0.02723, 'Adamax'),\n","               loss=\"binary_crossentropy\",\n","               metrics=[\"binary_accuracy\",\n","               tfa.metrics.F1Score(num_classes=2,\n","                                  average='micro',\n","                                  threshold=0.5),\n","               tf.keras.metrics.AUC(from_logits=False)\n","                        ])\n","\n","\n","  #return completed network\n","  return network\n","\n","# Wrap Keras model so it can be used by scikit-learn\n","neural_network = KerasClassifier(\n","                                 model=Neural_Net,\n","                                 epochs=250,\n","                                 batch_size=25,\n","                                 verbose=0,\n","                                 callbacks=[WandbCallback()]\n","                                 )"]},{"cell_type":"markdown","metadata":{"id":"FCak3iqyHHvi"},"source":["---------------------------------------------------------------------------------------------------------------------\n","K_fold (Post-sweep) to provide a more robust evaluation of the model's performance and its ability to generalize to unseen data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WmKbXvk01qFa"},"outputs":[],"source":["#Setup stratified Kfold for cross validation\n","seed = 123457\n","np.random.seed(seed)\n","kfold = StratifiedKFold(n_splits=20, shuffle=True, random_state=seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kelkyfEm1qky"},"outputs":[],"source":["#shows how good the model is\n","predictions = cross_val_predict(neural_network, X_train, y_train, cv=kfold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9S_P8Ty1sMa"},"outputs":[],"source":["#Training Data Confusion Matirix (W/ Kfold CV)\n","#-----------------------------------------------------------------------------------------------------------\n","conf_matrix = confusion_matrix(y_train, predictions)\n","print(conf_matrix, '\\n')\n","\n","conf_matrix_n = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n","fig, ax = plt.subplots(figsize=(10,10))\n","sns.heatmap(conf_matrix_n, annot=True, fmt='.2f', cmap='YlGnBu',\n","            xticklabels=['Sim','Real'], yticklabels=['Sim','Real'])\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Training Data Confusion Matirix with StratifiedKFold')\n","plt.xticks(rotation=45)\n","plt.show(block=False)\n","\n","print('\\nF1 Score: {}'.format(\n","    f1_score(y_train, predictions, average='binary')))\n","print('Precision: {}'.format(\n","    precision_score(y_train, predictions, average='binary'))) #weighted to show AUC-Precision/Recall curve\n","print('Recall: {}'.format(\n","    recall_score(y_train, predictions, average='binary')))\n","print('Accuracy: {}'.format(\n","    accuracy_score(y_train, predictions, average='binary')))"]},{"cell_type":"markdown","metadata":{"id":"LuQPJx3aHrfM"},"source":["Test data confrimation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8QNuHhek1yJ5"},"outputs":[],"source":["model = Neural_Net()\n","#Fit the model\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=300, batch_size=100, callbacks=[WandbCallback()])\n","test_pred = model.predict(X_test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d2oiwAQ3up6P"},"outputs":[],"source":["#Training Data Confusion Matirix\n","#-----------------------------------------------------------------------------------------------------------\n","predictions = (model.predict(X_train) > 0.5).astype(\"int32\")\n","\n","\n","conf_matrix = confusion_matrix(y_train, predictions)\n","print(conf_matrix, '\\n')\n","\n","conf_matrix_n = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n","fig, ax = plt.subplots(figsize=(10,10))\n","sns.heatmap(conf_matrix_n, annot=True, fmt='.2f', cmap='YlGnBu',\n","            xticklabels=['Sim','Real'], yticklabels=['Sim','Real'])\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Training Data Confusion Matirix')\n","plt.xticks(rotation=45)\n","plt.show(block=False)\n","\n","print('\\nF1 Score: {}'.format(\n","    f1_score(y_train, predictions, average='binary')))\n","print('Precision: {}'.format(\n","    precision_score(y_train, predictions, average='binary'))) #weighted to show AUC-Precision/Recall curve\n","print('Recall: {}'.format(\n","    recall_score(y_train, predictions, average='binary')))\n","print('Accuracy: {}'.format(\n","    accuracy_score(y_train, predictions, average='binary')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pg3wFvAD129o"},"outputs":[],"source":["#Test Data Confusion Matirix\n","#-----------------------------------------------------------------------------------------------------------\n","predictions_test = (model.predict(X_test) > 0.5).astype(\"int32\")\n","\n","conf_matrix = confusion_matrix(y_test, predictions_test)\n","print(conf_matrix, '\\n')\n","\n","conf_matrix_n = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n","fig, ax = plt.subplots(figsize=(10,10))\n","sns.heatmap(conf_matrix_n, annot=True, fmt='.2f', cmap='YlGnBu',\n","            xticklabels=['Sim','Real'], yticklabels=['Sim','Real'])\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Test Data Confusion Matirix')\n","plt.xticks(rotation=45)\n","plt.show(block=False)\n","\n","print('\\nF1 Score: {}'.format(\n","    f1_score(y_test, predictions_test, average='binary')))\n","print('Precision: {}'.format(\n","    precision_score(y_test, predictions_test, average='binary'))) #weighted to show AUC-Precision/Recall curve\n","print('Recall: {}'.format(\n","    recall_score(y_test, predictions_test, average='binary')))\n","print('Accuracy: {}'.format(\n","    accuracy_score(y_test, predictions_test, average='binary')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"itBilx0D15HQ"},"outputs":[],"source":["model.layers[0].get_weights()[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTZputIesVZj"},"outputs":[],"source":["#Test Data Confusion Matirix (w/ Kfold CV)\n","#-----------------------------------------------------------------------------------------------------------\n","\n","#Test data with Kfold CV (shows how good the model is)\n","predictions = cross_val_predict(neural_network, X_test, y_test, cv=kfold)\n","\n","conf_matrix = confusion_matrix(y_test, predictions)\n","print(conf_matrix, '\\n')\n","\n","conf_matrix_n = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n","fig, ax = plt.subplots(figsize=(10,10))\n","sns.heatmap(conf_matrix_n, annot=True, fmt='.2f', cmap='YlGnBu',\n","            xticklabels=['Sim','Real'], yticklabels=['Sim','Real'])\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Test data Confusion Matirix with StratifiedKFold')\n","plt.xticks(rotation=45)\n","plt.show(block=False)\n","\n","print('\\nF1 Score: {}'.format(\n","    f1_score(y_test, predictions, average='binary')))\n","print('Precision: {}'.format(\n","    precision_score(y_test, predictions, average='binary')))\n","print('Recall: {}'.format(\n","    recall_score(y_test, predictions, average='binary')))\n","print('Accuracy: {}'.format(\n","    accuracy_score(y_test, predictions, average='binary')))"]},{"cell_type":"markdown","metadata":{"id":"gIP_Pofh3L79"},"source":["---------------------------------------------------------------------\n","Further Testing with new datasets of real and sim data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N3p32oiK3LYj"},"outputs":[],"source":["#Outside data model performance (Sim & Real data)\n","#----------------------------------------------------------------------------------------------------------\\\n","df_real1 = pd.read_csv('/content/drive/MyDrive/Lab Work/Zach/RealData/Blue Order 2 (Ready4_ML).csv')\n","df1 = pd.read_csv('/content/drive/MyDrive/Lab Work/Zach/mergedata/OldData/blueSIM_test1.csv')\n","\n","df_real1.rename(columns={'Run Time ': 'Run Time'}, inplace=True)\n","# Rename the 'B' column to 'C' in-place\n","df1.rename(columns={'Run Time ': 'Run Time'}, inplace=True)\n","\n","df2 = df_real1\n","\n","#Labelling datasets\n","df1['type'] = 0 #SimData\n","df2['type'] = 1 #RealData\n","df_combined = pd.concat([df1, df2])\n","\n","df_combined['topics'] = df_combined['topics'].apply(lambda x: x.replace(\" \", \"\"))\n","df_combined\n","\n","# Encode labels in column 'species'.\n","df_combined['topics']= label_encoder.fit_transform(df_combined['topics'])\n","df_combined['msg']= label_encoder.fit_transform(df_combined['msg'])\n","df_combined['node']= label_encoder.fit_transform(df_combined['node'])\n","\n","\n","#Setting our prediction target and dropping target columns from the main dataset\n","predict = 'type'\n","drops = ['Run Time', 'msg', 'node', 'topics']\n","X = df_combined.drop(predict, axis=1)\n","y = df_combined[predict]\n","print(X.head())\n","print(y.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-lktzCyWBCHp"},"outputs":[],"source":["#Test Data Confusion Matirix (SIM & REAL)\n","#-----------------------------------------------------------------------------------------------------------\n","\n","predictions_combined = (model.predict(X) > 0.5).astype(\"int32\")\n","\n","conf_matrix = confusion_matrix(y, predictions_combined)\n","print(conf_matrix, '\\n')\n","\n","conf_matrix_n = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n","fig, ax = plt.subplots(figsize=(10,10))\n","sns.heatmap(conf_matrix_n, annot=True, fmt='.2f', cmap='YlGnBu',\n","            xticklabels=['Sim','Real'], yticklabels=['Sim','Real'])\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Test data Confusion Matirix for Sim&Real data')\n","plt.xticks(rotation=45)\n","plt.show(block=False)\n","\n","print('\\nF1 Score: {}'.format(\n","    f1_score(y, predictions_combined, average='binary')))\n","print('Precision: {}'.format(\n","    precision_score(y, predictions_combined, average='binary')))\n","print('Recall: {}'.format(\n","    recall_score(y, predictions_combined, average='binary')))\n","print('Accuracy: {}'.format(\n","    accuracy_score(y, predictions_combined, average='binary')))"]},{"cell_type":"markdown","metadata":{"id":"bwYBjlVLDocx"},"source":["-------------------------------------\n","Testing with only fake data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7AFsLm3iB5yn"},"outputs":[],"source":["#Outside data model performance (Sim data ONLY)\n","#----------------------------------------------------------------------------------------------------------\n","df1 = pd.read_csv('/content/drive/MyDrive/Lab Work/Zach/mergedata/OldData/blueSIM_test1.csv')\n","df1.rename(columns={'Run Time ': 'Run Time'}, inplace=True)\n","df1['type'] = 0 #SimData\n","\n","\n","df1['topics'] = df1['topics'].apply(lambda x: x.replace(\" \", \"\"))\n","df1\n","\n","\n","# Encode labels in column 'species'.\n","df1['topics']= label_encoder.fit_transform(df1['topics'])\n","df1['msg']= label_encoder.fit_transform(df1['msg'])\n","df1['node']= label_encoder.fit_transform(df1['node'])\n","df1\n","\n","#Setting our prediction target and dropping target columns from the main dataset\n","predict = 'type'\n","drops = ['Run Time', 'msg', 'node', 'topics']\n","X = df1.drop(predict, axis=1)\n","y = df1[predict]\n","print(X.head())\n","print(y.head())\n","\n","#Test Data Confusion Matirix (SIM)\n","#-----------------------------------------------------------------------------------------------------------\n","\n","predictions_df1 = (model.predict(X) > 0.5).astype(\"int32\")\n","\n","conf_matrix = confusion_matrix(y, predictions_df1)\n","print(conf_matrix, '\\n')\n","\n","conf_matrix_n = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n","fig, ax = plt.subplots(figsize=(10,10))\n","sns.heatmap(conf_matrix_n, annot=True, fmt='.2f', cmap='YlGnBu',\n","            xticklabels=['Sim','Real'], yticklabels=['Sim','Real'])\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Sim data ONLY Confusion Matirix')\n","plt.xticks(rotation=45)\n","plt.show(block=False)\n","\n","print('\\nF1 Score: {}'.format(\n","    f1_score(y, predictions_df1, average='binary')))\n","print('Precision: {}'.format(\n","    precision_score(y, predictions_df1, average='binary')))\n","print('Recall: {}'.format(\n","    recall_score(y, predictions_df1, average='binary')))\n","print('Accuracy: {}'.format(\n","    accuracy_score(y, predictions_df1,average='binary')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-snooTV8DcvI"},"outputs":[],"source":["predictions_df1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WJOt7IjdDxCu"},"outputs":[],"source":["#Outside data model performance (Real data ONLY)\n","#----------------------------------------------------------------------------------------------------------\n","df1 = pd.read_csv('/content/drive/MyDrive/Lab Work/Zach/RealData/Blue Order 2 (Ready4_ML).csv')\n","df1.rename(columns={'Run Time ': 'Run Time'}, inplace=True)\n","df1['type'] = 1 #RealData\n","\n","\n","df1['topics'] = df1['topics'].apply(lambda x: x.replace(\" \", \"\"))\n","df1\n","\n","\n","# Encode labels in column 'species'.\n","df1['topics']= label_encoder.fit_transform(df1['topics'])\n","df1['msg']= label_encoder.fit_transform(df1['msg'])\n","df1['node']= label_encoder.fit_transform(df1['node'])\n","df1\n","\n","#Setting our prediction target and dropping target columns from the main dataset\n","predict = 'type'\n","drops = ['Run Time', 'msg', 'node', 'topics']\n","X = df1.drop(predict, axis=1)\n","y = df1[predict]\n","print(X.head())\n","print(y.head())\n","\n","#Test Data Confusion Matirix (REAL)\n","#-----------------------------------------------------------------------------------------------------------\n","\n","predictions_df1 = (model.predict(X) > 0.5).astype(\"int32\")\n","\n","conf_matrix = confusion_matrix(y, predictions_df1)\n","print(conf_matrix, '\\n')\n","\n","conf_matrix_n = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n","fig, ax = plt.subplots(figsize=(10,10))\n","sns.heatmap(conf_matrix_n, annot=True, fmt='.2f', cmap='YlGnBu',\n","            xticklabels=['Sim','Real'], yticklabels=['Sim','Real'])\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Real data ONLY Confusion Matirix')\n","plt.xticks(rotation=45)\n","plt.show(block=False)\n","\n","print('\\nF1 Score: {}'.format(\n","    f1_score(y, predictions_df1, average='binary')))\n","print('Precision: {}'.format(\n","    precision_score(y, predictions_df1, average='binary')))\n","print('Recall: {}'.format(\n","    recall_score(y, predictions_df1, average='binary')))\n","print('Accuracy: {}'.format(\n","    accuracy_score(y, predictions_df1,average='binary')))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZwIhqDc8ENO2"},"outputs":[],"source":["predictions_df1"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[{"file_id":"1ngdq1btvc_M6EQS9M5pqg_BNZvRKHaKt","timestamp":1689014203032},{"file_id":"1FzDKpezL46uKkO8m7y3R_XqW72ZXmmwK","timestamp":1688674996530},{"file_id":"1uYL932hNAlvA96gc_GinCg8e8KRDzTvI","timestamp":1688049471178}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}